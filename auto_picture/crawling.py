import os
import glob
import shutil
import json
import re
from icrawler.builtin import GoogleImageCrawler
from PIL import Image

# ì‘ì—… í´ë” & ìµœì¢… ì €ì¥ í´ë”
JSON_FOLDER = "../src/config/usercolorways7"  # JSONì´ ìˆëŠ” í´ë”
WORKSPACE_FOLDER = "./workspace"  # ì‘ì—… í´ë” (í˜„ì¬ ë””ë ‰í† ë¦¬)
FINAL_SAVE_FOLDER = "../public/keycap/"  # ë³‘í•©ëœ WebP ì €ì¥ í´ë”

MIN_IMAGE_COUNT = 10  # ìµœì†Œ ì´ë¯¸ì§€ ê°œìˆ˜
MAX_ITERATIONS = 5  # ìµœëŒ€ í¬ë¡¤ë§ ì‹œë„ íšŸìˆ˜

def safe_remove(filepath):
    """íŒŒì¼ ì‚­ì œ (ì˜ˆì™¸ ë°©ì§€)"""
    try:
        if os.path.exists(filepath):
            os.remove(filepath)
            print(f"ì‚­ì œ ì„±ê³µ: {filepath}")
    except Exception as e:
        print(f"íŒŒì¼ ì‚­ì œ ì˜¤ë¥˜: {filepath} ({e})")

def is_rendered_image(img):
    """ë Œë”ë§ ì´ë¯¸ì§€ ì—¬ë¶€ í™•ì¸ (EXIF ì •ë³´ ì—†ëŠ” ê²½ìš° ë Œë”ë§ ì´ë¯¸ì§€ë¡œ ê°„ì£¼)"""
    try:
        exif = img._getexif()
    except Exception:
        exif = None
    return exif is None

def process_images_from_folder(temp_folder, valid_images, remaining_needed):
    """ë‹¤ìš´ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ WebPë¡œ ë³€í™˜"""
    count_added = 0
    for filepath in glob.glob(os.path.join(temp_folder, '*')):
        if count_added >= remaining_needed:
            break
        try:
            with Image.open(filepath) as img:
                img.load()
                width, height = img.size

                # í•´ìƒë„ ì¡°ê±´ í™•ì¸ (ë„ˆë¹„ 800px ì´ìƒë§Œ ì‚¬ìš©)
                if width < 800:
                    safe_remove(filepath)
                    continue

                # ë Œë”ë§ ì´ë¯¸ì§€ íŒë³„
                if not is_rendered_image(img):
                    safe_remove(filepath)
                    continue

                # ê°€ë¡œ 800pxë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                scale = 800 / width
                img_resized = img.resize((800, int(height * scale)), Image.LANCZOS)

                # WebPë¡œ ì €ì¥
                base_name = os.path.splitext(os.path.basename(filepath))[0]
                final_filepath = os.path.join(temp_folder, base_name + '.webp')
                img_resized.save(final_filepath, 'WEBP', quality=75, optimize=True)

                # ë©”ëª¨ë¦¬ í•´ì œ
                img_resized.close()
                img.close()
                valid_images.append(final_filepath)
                count_added += 1

                # ì›ë³¸ ì‚­ì œ
                safe_remove(filepath)

        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {filepath} ({e})")
            safe_remove(filepath)
    return count_added

def merge_images_into_scrollable(image_files, output_filepath):
    """ì´ë¯¸ì§€ë“¤ì„ ê°€ë¡œë¡œ ë³‘í•©í•˜ì—¬ íˆ¬ëª… ë°°ê²½ WebP ìƒì„±"""
    if len(image_files) < MIN_IMAGE_COUNT:
        print(f"âŒ ìµœì†Œ {MIN_IMAGE_COUNT}ê°œ í•„ìš”í•˜ì§€ë§Œ, {len(image_files)}ê°œë§Œ ìˆìŒ. ë³‘í•© ì·¨ì†Œ.")
        return None

    images = [Image.open(img).convert("RGBA") for img in image_files]  # RGBA ë³€í™˜
    total_width = sum(img.width for img in images)
    max_height = max(img.height for img in images)

    if total_width == 0 or max_height == 0:
        print("âŒ ë³‘í•© ì‹¤íŒ¨: ì´ë¯¸ì§€ í¬ê¸°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŒ.")
        return None

    # íˆ¬ëª… ë°°ê²½ ìƒì„± (RGBA ëª¨ë“œ)
    merged_image = Image.new('RGBA', (total_width, max_height), (0, 0, 0, 0))

    x_offset = 0
    for img in images:
        merged_image.paste(img, (x_offset, 0), mask=img)  # íˆ¬ëª… ë¶€ë¶„ ìœ ì§€
        x_offset += img.width
        img.close()

    try:
        merged_image.save(output_filepath, 'WEBP', quality=75, lossless=True)  # íˆ¬ëª… WebP ì €ì¥
        print(f"âœ… '{output_filepath}' (íˆ¬ëª… ë°°ê²½) ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ WebP ì €ì¥ ì˜¤ë¥˜: {e}")
        return None

    return output_filepath

def extract_labels_from_json():
    """JSON íŒŒì¼ì—ì„œ label ê°’ ì¶”ì¶œ (mkg_ ì œê±°)"""
    labels = []
    for json_file in glob.glob(os.path.join(JSON_FOLDER, '*.json')):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if 'label' in data:
                    label = data['label'].replace("mkg_", "")  # 'mkg_' ì ‘ë‘ì‚¬ ì œê±°
                    labels.append((json_file, label))
        except Exception as e:
            print(f"JSON ì½ê¸° ì˜¤ë¥˜: {json_file} ({e})")
    return labels

def process_labels():
    """JSONë³„ labelì„ ê²€ìƒ‰í•˜ì—¬ ì´ë¯¸ì§€ í¬ë¡¤ë§ ë° ë³‘í•©"""
    labels = extract_labels_from_json()
    if not labels:
        print("âŒ JSON íŒŒì¼ì—ì„œ ê²€ìƒ‰í•  labelì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    os.makedirs(WORKSPACE_FOLDER, exist_ok=True)  # ì‘ì—… í´ë” ìƒì„±
    os.makedirs(FINAL_SAVE_FOLDER, exist_ok=True)  # ìµœì¢… ì €ì¥ í´ë” ìƒì„±

    for json_file, label in labels:
        print(f"\nğŸ” '{label}' ê²€ìƒ‰ ì¤‘...")

        # ê°œë³„ ì‘ì—… í´ë”
        temp_dir = os.path.join(WORKSPACE_FOLDER, label)
        os.makedirs(temp_dir, exist_ok=True)

        valid_images = []  # ê°œë³„ JSONì— ëŒ€í•œ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
        iteration = 0

        # ìµœì†Œ 10ê°œ ì´ë¯¸ì§€ í™•ë³´ë  ë•Œê¹Œì§€ ë°˜ë³µ ë‹¤ìš´ë¡œë“œ
        while len(valid_images) < MIN_IMAGE_COUNT and iteration < MAX_ITERATIONS:
            iteration += 1
            remaining_needed = MIN_IMAGE_COUNT - len(valid_images)

            print(f"[Iteration {iteration}] '{label}' ì¶”ê°€ ë‹¤ìš´ë¡œë“œ ({remaining_needed}ê°œ í•„ìš”)...")

            google_crawler = GoogleImageCrawler(storage={'root_dir': temp_dir})
            google_crawler.crawl(keyword=label, max_num=remaining_needed * 3)

            added = process_images_from_folder(temp_dir, valid_images, remaining_needed)
            print(f"âœ… {added}ê°œ ì¶”ê°€ë¨ (í˜„ì¬ {len(valid_images)}/{MIN_IMAGE_COUNT})")

        # 10ê°œ ë¯¸ë§Œì´ë©´ ìŠ¤í‚µ
        if len(valid_images) < MIN_IMAGE_COUNT:
            print(f"âŒ '{label}' ê²€ìƒ‰ ê²°ê³¼ ë¶€ì¡± (ìµœì†Œ 10ê°œ í•„ìš”, {len(valid_images)}ê°œ í™•ë³´)")
            shutil.rmtree(temp_dir, ignore_errors=True)
            continue

        # JSON íŒŒì¼ëª…ê³¼ ë™ì¼í•œ WebP ìƒì„±
        json_filename = os.path.splitext(os.path.basename(json_file))[0] + ".webp"
        merged_image_path = os.path.join(temp_dir, json_filename)
        merged_image = merge_images_into_scrollable(valid_images, merged_image_path)

        # ë³‘í•©ëœ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì—ˆìœ¼ë©´ ìµœì¢… ì €ì¥ í´ë”ë¡œ ì´ë™
        if merged_image:
            final_destination = os.path.join(FINAL_SAVE_FOLDER, json_filename)
            shutil.move(merged_image, final_destination)
            print(f"ğŸš€ '{final_destination}' ì´ë™ ì™„ë£Œ")

        # ì‘ì—… í´ë” ì‚­ì œ
        shutil.rmtree(temp_dir, ignore_errors=True)

    print("âœ… ëª¨ë“  JSON ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == '__main__':
    process_labels()
